---
title: "Identify FAO and OHI regions for RAM stocks. From OHI 2020: Food Provision/Fisheries, Identify FAO and OHI regions for RAM stocks"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"

---

```{r}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
```

## Summary

Generates a dataset describing the OHI and FAO major fishing regions that correspond to each stock's range.  This combines last year's dataset of stock-spatial information from RAM v4.44 database and Christopher M. Free's spatial work at Rutgers as well as newly added stocks from RAM v4.491 with manually assigned ohi and fao region ids. Dataset only contains stocks with B/Bmsy data.

https://marine.rutgers.edu/~cfree/ram-legacy-stock-boundary-database/

https://marine.rutgers.edu/~cfree/mapping-africas-fish-stock-boundaries/
https://marine.rutgers.edu/~cfree/mapping-south-american-fish-stock-boundaries/
https://marine.rutgers.edu/~cfree/mapping-global-tuna-marlin-and-swordfish-stocks/
https://marine.rutgers.edu/~cfree/mapping-fish-stocks-in-russia-taiwan-iran-antarctica-and-north-pacific/ : I delineated the CCAMLR Ross Sea Antarctic toothfish (Dissostichus spp.) stock using FAO Statistical Subareas 88.1 and 88.2.
https://marine.rutgers.edu/~cfree/mapping-canadas-fishing-areas/
https://marine.rutgers.edu/~cfree/mapping-europes-fish-stock-boundaries/
https://marine.rutgers.edu/~cfree/mapping-the-usas-fish-stock-boundaries/

## Updates for 2020

There were some duplicates showing up in the data, so we fixed those. 

## Setup

```{r}

## Libraries
library(dplyr)
library(tidyr)
library(readr)
library(sf)
library(ggplot2)
library(stringr)
library(here) 
setwd(here::here("globalprep","fis","v2020"))

source('../../../workflow/R/common.R')

```

## Identify Newly Added Stocks

Compare stocks found in previous version of RAM data to new data to see what additional stocks have been added.

Old Stocks: Used `timeseries` table, because in RAM v3.80, this table only contained single assessment for each unique stock. Now we use `timeseries_values_view, since v4.44 (assessment year 2019). 
```{r}

## old stocks
load(file.path(dir_M, "git-annex/globalprep/_raw_data/RAM/d2019/RLSADB v4.44/DB Files With Assessment Data/DBdata.RData"))

ram_bmsy_old <- timeseries_values_views %>%
dplyr::select(stockid, stocklong, year, TBdivTBmsy, SSBdivSSBmsy, TBdivTBmgt, SSBdivSSBmgt) %>%
  mutate(ram_bmsy = 
           ifelse(!is.na(TBdivTBmsy), TBdivTBmsy, SSBdivSSBmsy)) %>%
  mutate(ram_bmsy =
           ifelse(is.na(TBdivTBmsy) & is.na(SSBdivSSBmsy), TBdivTBmgt, ram_bmsy)) %>%
  mutate(ram_bmsy = 
           ifelse(is.na(TBdivTBmsy) & is.na(SSBdivSSBmsy) & is.na(TBdivTBmgt), SSBdivSSBmgt, ram_bmsy)) %>%
  dplyr::filter(year > 1979) %>%
  filter(!is.na(ram_bmsy)) %>%
  dplyr::select(stockid, stocklong, year, ram_bmsy)

## check number of unique entries
old_stockid <- unique(ram_bmsy_old$stockid) # 442 unique entries

```

New Stocks: Used `timeseries_values_views` table, because in RAM v4.44, this is the table that contains the most recent assessment for each unique stock. The `timeseries` table has all assessments conducted so there are multiple `assessid` per unique `stockid`.
```{r}
## new stocks
load(file.path(dir_M, "git-annex/globalprep/_raw_data/RAM/d2020/RAMLDB v4.491/DB Files With Assessment Data/R Data/DBdata[asmt][v4.491].RData"))

ram_bmsy <- timeseries_values_views %>%
dplyr::select(stockid, stocklong, year, TBdivTBmsy, SSBdivSSBmsy, TBdivTBmgt, SSBdivSSBmgt) %>%
  mutate(ram_bmsy = 
           ifelse(!is.na(TBdivTBmsy), TBdivTBmsy, SSBdivSSBmsy)) %>%
  mutate(ram_bmsy =
           ifelse(is.na(TBdivTBmsy) & is.na(SSBdivSSBmsy), TBdivTBmgt, ram_bmsy)) %>%
  mutate(ram_bmsy = 
           ifelse(is.na(TBdivTBmsy) & is.na(SSBdivSSBmsy) & is.na(TBdivTBmgt), SSBdivSSBmgt, ram_bmsy)) %>% 
  filter(!is.na(ram_bmsy)) %>% 
  dplyr::filter(year > 1979) %>%
  dplyr::select(stockid, stocklong, year, ram_bmsy)

## check number of unique entries
new_stockid <- unique(ram_bmsy$stockid) # 443 unique entries
```


### Investigate Differences
There were 4 stocks included in the new data but not the old data.
These include: 

* "BTSHRIMPNAUST"  "COD1f-XIV" "GTPRAWNNAUST"  "SARDWSE"      

There were 3 stocks present in the old data but not the new.
These include:

* "CODIf-XIV"               "REDDEEPDP-1-2-V-XII-XIV" "RSARDINWA"    - in OLD RAM 4.44



```{r}

## find newly added stocks, when using timeseries_values_views
newStocks <- setdiff(new_stockid, old_stockid) # there are 4 new stocks
unusedStocks <- setdiff(old_stockid, new_stockid) # these are no longer included in the RAM data, will be deleted

# v2020: See the mispelling for CODIf-XIV vs COD1f-XIV. This is ok. We will just use the new spelling and assign the fao-ohi regions again. 
```


Subset for just the additional stocks in RAM v4.491 data
```{r}

ram_bmsy_new <- ram_bmsy %>% 
  filter(stockid %in% newStocks) 

id_new <- ram_bmsy_new %>% 
  select(stockid, stocklong) %>% 
  distinct()

```


## Add Stock Info to Old RAM_fao_ohi_rgns

Each stock needs the corresponding ohi and fao regions associated with its range.  For the most part, we can use the data from last year, and add the data for the new regions.  However, the old data uses "assessid", but we now need to replace this with the stock id and stock long because assessid is no longer used in the new version of the data.  The stock long and stock id  is obtained from the old RAM B/Bmsy data and merged with the RAM_fao_ohi_rgn data (done below).
```{r}
## Grab last year's fao-ohi-assessid data table
## (we need to get the stock id from the old RAM data)
RAM_fao_ohi_rgns <- read.csv("../v2019/int/RAM_fao_ohi_rgns_final.csv") 

######### This part is only needed for v2020...
#after some investigating it was found that there are a ton of duplicates in this file. This is a mistake. Every stock should only have one unique combo of each rgn id and fao id. We need to isolate and remove these. First we will remove the easy ones using distinct(), then we will isolate the outliers with more than one duplicate.

RAM_fao_ohi_rgns_fix <- RAM_fao_ohi_rgns %>%
  distinct() %>% ## fixes easy duplicates. Now lets check for mispellings or other errors 
  group_by(rgn_id, fao_id, stockid) %>%
  dplyr::mutate(dupe = n()>1) %>% # find the rest of the duplicates 
  ungroup()
  
 #filter for duplicates
dupes <- RAM_fao_ohi_rgns_fix %>%
filter(dupe == "TRUE") 

dupes$stockid #these are our problem duplicates: OROUGHYNWCR and PERCHQCI

## fix the dupes 
dupes_fix <- dupes %>%
  filter(!is.na(RAM_area_m2))

##filter out dupes from RAM_fao_ohi_rgns_fix and add fixed dupes back in
RAM_fao_ohi_rgns_fix_final <- RAM_fao_ohi_rgns_fix %>%
  filter(dupe == "FALSE") %>%
  rbind(dupes_fix) %>%
  select(-dupe) ## now we have fixed the duplicate problem. 

######### end part only needed for v2020. However, in the future, we should always check for duplicates to make sure this isn't overlooked again! 

## create unique values of assessid, stock id, and stock long
id_old <- ram_bmsy_old %>% 
  select(stockid, stocklong) %>% 
  distinct()

## join tables
RAM_rgns_old <- RAM_fao_ohi_rgns_fix_final %>% 
  full_join(id_old, by=c("stockid", "stocklong")) 

```


## remove stocks that are no longer in the RAM data
(but were in the previous version)

```{r}
filter(RAM_rgns_old, stockid %in% unusedStocks) # quick check

RAM_rgns_old <- RAM_rgns_old %>%
  filter(!(stockid %in% unusedStocks))
```

```{r}
#### 2020 fix only ####
# because of a few spelling changes in stocklong, a couple of the stocks that were already present in the 2019 data are showing up as NA for FAO and RGN ID in the 2020 data. Spot check each of the stocks that show up in RAM_filt with RAM_rgns_new. We need to make sure that each stock only shows up once unless it is in multiple FAO/ohi regions. 

o_roughy_RAM <- RAM_rgns_old %>%
  filter(stockid == "OROUGHYNWCR") ## bad, need to remove 1 of these rows (only keep the one with area in it). This was filled in last year. 

perch_RAM <- RAM_rgns_old %>%
  filter(stockid == "PERCHQCI") # bad, only want to keep 1 of these. This was filled in last year. 

# i will go in and fix these myself in excel, and re upload. I deleted the two NA rows for PERCHQCI and OROUGHYNWCR, and fixed the stocklong spelling to match the 2020 data. 
write.csv(RAM_rgns_old, file.path("int/RAM_fix_2020.csv"), row.names = FALSE)

## reupload as "RAM_fix_2020_corr.csv
RAM_rgns_old <- read_csv(file.path("int/RAM_fix_2020_corr.csv"))

#### END 2020 FIX ####
```

## Combine New and Old Stock Data

Essentially adds new stocks to the bottom of the old stocks data table.  The regions of the new stocks are blank at this point. 
```{r}

## Make sure these new species aren't in the old data
setdiff(id_new$stockid, RAM_rgns_old$stockid)


RAM_rgns_new <- RAM_rgns_old %>% 
  full_join(id_new, by = c("stockid","stocklong")) ## added the 4 new stocks.


```

## Fill Region IDs for New Stocks

Investigate what FAO/OHI region each stock belongs to: 
* Full intermediate stock data table [here](https://github.com/OHI-Science/ohiprep_v2020/master/globalprep/fis/v2019/int/RAM_fao_ohi_rgns.csv)
* Primarily used www.fishsource.org to find stock distribution information. ICES sub-region codes found here: https://www.researchgate.net/figure/Stock-units-defined-by-ICES-for-white-anglerfish-southern-stock-in-Divisions-VIIIc-and_fig1_31198841 and http://gis.ices.dk/sf/
* Referenced F_CODE/FAO_AREAS (filtered for MAJOR in F_LEVEL) in ohi_fao_rgns shapefile (fis/v2017/int) from mazu (can use other map visuals to identify stock extent). 
* Searched and tested key words in data table viewer (`DT::datatable`) to use in `str_detect`. See which stocks have the same FAO id assignment(s).

Some regions have more than 1 `fao_id` or `rgn_id` (e.g. Alaska skate Bering Sea and Aleutian Islands,	Kamchatka flounder Bering Sea and Aleutian Islands have `fao_id` 61 and 67).

Note: In `str_detect`, it doesn't always work when you type out "Bering Sea | Gulf of Alaska$". Using `paste` with the `collapse = "|"` argument seems to work best.


```{r}
## v2020: you can see there are more than 4 here stocks here. This is because some must've been overlooked in past data preps. We will manually add the FAO and OHI regions for all of the NA stocks here. 


# Atlantic cod NAFO 1f and ICES 14 has ohi rgn *145* and fao rgn 21, 27 - -
# Brown tiger shrimp Northern Australia fao rgn 57, 71, and ohi rgn *16* - - 
# Grooved tiger prawn Northern Australia fao rgn 57, 71, and ohi rgn *16*- - 
# Norway lobster Adriatic Sea fao rgn 37, ohi rgn *184*, *187* *186*, *232* *82* *80* - -
# Sand eel Sandeel Area 4 fao rgn 27, ohi rgn *223* - - 
# Sardine Western half of Southeast Australia ohi rgn *16*, fao rgn 57 - - 
# Spurdog Northeast Atlantic fao rgn 21, ohi rgn *163*, *218* - - 

## Subset for rows with missing FAO and OHI ids
RAM_filt <- RAM_rgns_new %>% 
  filter(is.na(fao_id))


RAM <- RAM_filt %>%
  ## ADDING FAO REGION ID
  mutate(fao_id = 
           case_when(
             str_detect(stocklong, paste(c("Atlantic cod", "Sand eel", "Boarfish VI"), collapse = "|")) ~ 27,
             str_detect(stocklong, paste(c("Northern Australia", "Southeast Australia"), collapse = "|")) ~ 57,
             str_detect(stocklong, paste(c("Spurdog"), collapse = "|")) ~ 21,
             str_detect(stocklong, paste(c("Norway lobster"), collapse = "|")) ~ 37
           )) %>%
  mutate(fao_id_2 =
           case_when(
             str_detect(stocklong, paste(c("Atlantic cod"), collapse = 
                        "|")) ~ 21,
             str_detect(stocklong, paste(c("Northern Australia"), collapse = "|")) ~ 71
           )) %>%
  ## ADDING OHI REGION ID
  mutate(rgn_id = 
           case_when(
             str_detect(stocklong, paste(c("Atlantic cod"), collapse = "|")) ~ 145,
             str_detect(stocklong, paste(c("Spurdog"), collapse = "|")) ~ 163,
             str_detect(stocklong, paste(c("Australia"), collapse = "|")) ~ 16, 
             str_detect(stocklong, paste(c("Sandeel"), collapse = "|")) ~ 223,
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 184
             
           )) %>%
  mutate(rgn_id_2 =
           case_when(
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 187, 
             str_detect(stocklong, paste(c("Spurdog"), collapse = "|")) ~ 218,

           )) %>%
  mutate(rgn_id_3 =
           case_when(
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 186
           )) %>%
  mutate(rgn_id_4 =
           case_when(
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 232
           )) %>%
  mutate(rgn_id_5 =
           case_when(
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 82
           )) %>%
  mutate(rgn_id_6 =
           case_when(
             str_detect(stocklong, paste(c("Norway"), collapse = "|")) ~ 80
           ))
             
DT::datatable(RAM,rownames = F)

```

## Tidy Final Datatable

### Gather FAO and OHI ids into long format

```{r}

RAM_temp <- RAM %>% 
  gather(fao, fao_values, contains("fao_id")) %>% 
  rename(fao_id = fao_values) %>% 
  select(-fao) %>% 
  gather(ohi, ohi_values, contains("rgn_id")) %>% 
  rename(rgn_id = ohi_values) %>% 
  select(-ohi) %>% 
  filter(!is.na(fao_id), !is.na(rgn_id)) %>%
  arrange(stockid, fao_id, rgn_id)

```

### Fix Incorrect FAO-OHI Matches

Each row must have both an FAO id and a rgn id. Fix duplicate/incorrect fao-ohi matches by using ohi_fao_rgns spatial file
```{r}

## Spatial file with fao and ohi regions, F_CODE is the FAO id
fao_ohi <- st_read(dsn = file.path(dir_M, "git-annex/globalprep/fis/v2017/int"),
                   layer = "ohi_fao_rgns")
st_geometry(fao_ohi) <- NULL # removes geometry

fao_ohi_id <- fao_ohi %>%
  select(rgn_id, fao_id = F_CODE) %>% 
  arrange(rgn_id) %>% 
  mutate(fao_id = as.numeric(as.character(fao_id))) %>% 
  mutate(rgn_id = as.numeric(as.character(rgn_id))) %>% 
  distinct()

## Filter for correct fao-ohi pairs in the RAM regions table 
RAM_rgns_new_final <- fao_ohi_id %>% 
  left_join(RAM_temp, by = c("rgn_id", "fao_id")) %>% 
  filter(!is.na(stockid)) %>% # keep matches only
 arrange(stocklong, fao_id)


```

Compare with unfiltered RAM regions table to check on fao-ohi pairs that were dropped
```{r}
## Number of unique stocks after joining
nrow(RAM_rgns_new_final) #16
## Number of unique stocks before joining
RAM_temp <- RAM_temp %>% select(rgn_id, fao_id, stockid, stocklong) %>% distinct() %>% arrange(stocklong, fao_id)
nrow(RAM_temp) #16

## add identifier for the two RAM table versions
RAM_temp$idtemp <- 1:nrow(RAM_temp)
RAM_rgns_new_final$idtemp2 <- 1:nrow(RAM_rgns_new_final)

## view the ohi-fao pairs that would be removed
combine <- RAM_temp %>% 
  full_join(RAM_rgns_new_final, by = c("rgn_id", "fao_id", "stockid", "stocklong")) %>% 
  filter(is.na(idtemp2)) ## 0 for 2020 yay!

```

Tidy up RAM data table.  After the final check (located below), I hand added some new regions for some of the stocks. 
```{r}

write.csv(RAM_rgns_new_final, "int/RAM_new_stocks.csv", row.names=FALSE)
## check that there are still 9 unique stock ids
length(unique(RAM_rgns_new_final$stockid)) # 7 makes sense

```

### Final check
The goal here is to make sure we are capturing all the ohi/fao regions that the stock is caught in. I'm just going focus on the newly added stocks. After examining this table, I added in some more regions relevant to particular stocks, and saved the changes as "RAM_new_stocks_hand_additions.csv" (and then reran through the code with the new file.).
```{r, eval=FALSE}
ram <- read.csv("int/RAM_new_stocks.csv")

ram$idtemp2 <- 1:nrow(ram)

ram_sp <- ram %>%
  left_join(data.frame(metadata), by = "stockid") %>%
  dplyr::select(rgn_id, fao_id, stockid, stocklong=stocklong.x, scientificname, commonname, idtemp2)

# Watson species, sci name (read in the datatable that includes TaxonKey)
wat_sp <- read_csv(file.path(dir_M,'git-annex/globalprep/fis/v2020/int/stock_catch_by_rgn_taxa.csv')) %>% 
  dplyr:: select(rgn_id, fao_id=fao_rgn, scientificname=TaxonName, stock_id) %>%
  unique() 

wat_sp_w_RAM <- filter(wat_sp, scientificname %in% ram_sp$scientificname)

combined <- left_join(wat_sp_w_RAM, ram_sp, by=c("rgn_id", "fao_id", "scientificname")) %>%
  arrange(scientificname, stockid, fao_id, rgn_id,)

write.csv(combined, "int/watson_RAM_rgn_compare.csv", row.names=FALSE)

combined <- read_csv(file.path("int/watson_RAM_rgn_compare.csv"))


#### The way to hand check these are to look at stock_ids which have an idtemp2. I.e. Penaeus_semisulcatus-71, filter for this stock_id, and hand check the rgn_id's that have NAs as stockids to determine if these rgn_id's should be hand added to our RAM_new_stocks according to the fisheries listed on fishsource.org for each species

#2020
## Penaeus_semisulcatus-71 need to add none... this is only fished by australia according to fishsource, which is already present, rgnid 16
## Penaeus_semisulcatus-57 need to add none... this is only fished by australia according to fishsource, which is already present, rgnid 16
## Sardinops_sagax-57	need to add none... this is only fished by australia according to fishsource, which is already present, rgnid 16
## Gadus_morhua-27 need to add none... this is only fished by greenland according to fishsource, which is already present. A good check here is because stocklong indicates that it is in ICES subarea 14, and NAFO 1f, which are only in greenland. 
## Gadus_morhua-21 need to add none... this is only fished by greenland according to fishsource, which is already present. A good check here is because stocklong indicates that it is in ICES subarea 14, and NAFO 1f, which are only in greenland. 
## Hoplostethus_atlanticus-81	need to add none. This is only fished by NZ, rgn id =162. Here is the link to check. I knew it was this by looking at stocklong: https://www.fishsource.org/stock_page/1410
## Squalus_acanthias-21	 Need to add none.. See these links for reference: https://www.fishsource.org/stock_page/1683; https://www.fishsource.org/stock_page/1684. We know that these are only in FAO 21 based on stocklong. 
## Nephrops_norvegicus-37. need to add none. We know this is located in the Adriatic Sea (see stocklong), and all of those countries are present.

# Once finished spot checking and adding some, reupload to int as "RAM_new_stocks_hand_additions.csv" so that we document this. Then go back to the part of the code where we manually add in rgn ids and fao ids for species, and add these (The part titled "Fill Region IDs for new stocks"). Now rerun the code from there! Note: since we didn't have any hand additions for 2020, no need to go back and add them! 

```

### Combine with full dataset

Combine newly added stocks with ohi and fao region information to the old stock data table. Make sure there are no NAs!
```{r, eval=FALSE}


RAM_final <- bind_rows(read_csv(file.path("int/RAM_new_stocks.csv")),
                            read_csv("int/RAM_new_stocks_hand_additions.csv", col_types = "ddccd")) %>% 
  select(-idtemp2)

RAM_fao_ohi_rgn_final <- RAM_rgns_old %>% 
  full_join(RAM_final, by = c("rgn_id", "fao_id", "stockid", "stocklong")) %>%
  select(-RAM_area_m2.y, RAM_area_m2 = RAM_area_m2.x) %>%
  filter(!is.na(fao_id)) # only do this for 2020. For some reason NAs were carried over from 2019, that we filled in this year. 
 

write.csv(RAM_fao_ohi_rgn_final, "int/RAM_fao_ohi_rgns_final.csv", row.names=FALSE)
```
